{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ff5fe36-9b81-4a6b-a058-e156573245d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèéÔ∏è F1 DRIVER ONBOARD MOTION TRACKER V2.0\n",
      "======================================================================\n",
      "‚úÖ Imports loaded\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 1: Setup & Imports\n",
    "# ============================================================================\n",
    "# F1 DRIVER ONBOARD MOTION TRACKER V2.0\n",
    "# Professional driver motion masking with elegant visualization\n",
    "# Based on FrameShift V1.1 architecture\n",
    "# ============================================================================\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "from collections import deque\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "print(\"üèéÔ∏è F1 DRIVER ONBOARD MOTION TRACKER V2.0\")\n",
    "print(\"=\"*70)\n",
    "print(\"‚úÖ Imports loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bacc59a3-e8db-45e1-a664-b8a2a30aebcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Configuration loaded\n",
      "   bg_history: 500\n",
      "   bg_var_threshold: 25\n",
      "   detect_shadows: False\n",
      "   learning_rate: 0.001\n",
      "   denoise_strength: 5\n",
      "   ... and 29 more settings\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 2: Configuration\n",
    "# ============================================================================\n",
    "\n",
    "CONFIG = {\n",
    "    # Background subtraction settings\n",
    "    'bg_history': 500,              # Frames to learn background\n",
    "    'bg_var_threshold': 25,         # Sensitivity (lower = more sensitive)\n",
    "    'detect_shadows': False,        # Ignore shadows\n",
    "    'learning_rate': 0.001,         # How fast to adapt to changes\n",
    "    \n",
    "    # Preprocessing\n",
    "    'denoise_strength': 5,          # Reduce camera noise\n",
    "    'apply_clahe': True,            # Enhance contrast\n",
    "    'clahe_clip_limit': 2.0,\n",
    "    'clahe_grid_size': (8, 8),\n",
    "    \n",
    "    # Mask refinement\n",
    "    'morphology_iterations': 2,     # Clean up mask\n",
    "    'open_kernel_size': (3, 3),     # Remove small noise\n",
    "    'close_kernel_size': (9, 9),    # Fill holes\n",
    "    'dilate_kernel_size': (5, 5),   # Expand mask slightly\n",
    "    \n",
    "    # Motion filtering\n",
    "    'min_motion_area': 200,         # Minimum pixels for motion\n",
    "    'max_motion_area': 50000,       # Maximum pixels (full hands)\n",
    "    'temporal_smoothing': True,     # Smooth over time\n",
    "    'smooth_window': 5,             # Frames to average\n",
    "    \n",
    "    # ROI (Region of Interest) - Focus on driver area\n",
    "    'use_roi': True,                # Enable ROI\n",
    "    'roi_coords': None,             # Auto-detect or manual (x, y, w, h)\n",
    "    'roi_padding': 0.1,             # 10% padding around detected area\n",
    "    \n",
    "    # Visualization\n",
    "    'output_mode': 'overlay',       # 'mask', 'overlay', 'side_by_side', 'heatmap'\n",
    "    'mask_color': (0, 255, 0),      # Green for motion\n",
    "    'overlay_alpha': 0.6,           # Transparency\n",
    "    'show_contours': True,          # Draw motion boundaries\n",
    "    'contour_color': (0, 255, 255), # Yellow contours\n",
    "    'contour_thickness': 2,\n",
    "    'show_trails': True,            # Show motion trails\n",
    "    'trail_length': 15,             # Frames in trail\n",
    "    'trail_color': (255, 0, 255),   # Magenta trails\n",
    "    \n",
    "    # Output\n",
    "    'output_codec': 'mp4v',         # Video codec\n",
    "    'output_quality': 95,           # JPEG quality for preview\n",
    "    'show_preview': False,          # Live preview window (disable for headless OpenCV)\n",
    "    'preview_scale': 0.6,           # Scale for preview\n",
    "    'save_debug_frames': False,     # Save individual frames\n",
    "    'debug_interval': 30,           # Save every N frames\n",
    "}\n",
    "\n",
    "print(\"üìã Configuration loaded\")\n",
    "for key, value in list(CONFIG.items())[:5]:\n",
    "    print(f\"   {key}: {value}\")\n",
    "print(f\"   ... and {len(CONFIG)-5} more settings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8f1a66a-b1e9-4ff6-9628-bb772f786716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Utility functions defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 3: Utility Functions\n",
    "# ============================================================================\n",
    "\n",
    "def select_video_gui():\n",
    "    \"\"\"Open file dialog to select video\"\"\"\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    root.attributes('-topmost', True)\n",
    "    \n",
    "    print(\"üìÇ Select F1 onboard video...\")\n",
    "    video_path = filedialog.askopenfilename(\n",
    "        title=\"Select F1 Onboard Video\",\n",
    "        filetypes=[\n",
    "            (\"Video files\", \"*.mp4 *.avi *.mov *.mkv\"),\n",
    "            (\"All files\", \"*.*\")\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    root.destroy()\n",
    "    return video_path\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    \"\"\"Apply preprocessing to improve motion detection\"\"\"\n",
    "    processed = frame.copy()\n",
    "    \n",
    "    # 1. Denoise\n",
    "    if CONFIG['denoise_strength'] > 0:\n",
    "        processed = cv2.fastNlMeansDenoisingColored(\n",
    "            processed, None, \n",
    "            CONFIG['denoise_strength'], \n",
    "            CONFIG['denoise_strength'], 7, 21\n",
    "        )\n",
    "    \n",
    "    # 2. Enhance contrast with CLAHE\n",
    "    if CONFIG['apply_clahe']:\n",
    "        lab = cv2.cvtColor(processed, cv2.COLOR_BGR2LAB)\n",
    "        l, a, b = cv2.split(lab)\n",
    "        \n",
    "        clahe = cv2.createCLAHE(\n",
    "            clipLimit=CONFIG['clahe_clip_limit'],\n",
    "            tileGridSize=CONFIG['clahe_grid_size']\n",
    "        )\n",
    "        l = clahe.apply(l)\n",
    "        \n",
    "        processed = cv2.merge([l, a, b])\n",
    "        processed = cv2.cvtColor(processed, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    return processed\n",
    "\n",
    "def refine_mask(mask):\n",
    "    \"\"\"Clean up and refine the motion mask\"\"\"\n",
    "    refined = mask.copy()\n",
    "    \n",
    "    # 1. Morphological operations\n",
    "    kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, CONFIG['open_kernel_size'])\n",
    "    kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, CONFIG['close_kernel_size'])\n",
    "    kernel_dilate = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, CONFIG['dilate_kernel_size'])\n",
    "    \n",
    "    # Remove small noise\n",
    "    for _ in range(CONFIG['morphology_iterations']):\n",
    "        refined = cv2.morphologyEx(refined, cv2.MORPH_OPEN, kernel_open)\n",
    "    \n",
    "    # Fill holes\n",
    "    for _ in range(CONFIG['morphology_iterations']):\n",
    "        refined = cv2.morphologyEx(refined, cv2.MORPH_CLOSE, kernel_close)\n",
    "    \n",
    "    # Expand slightly to capture full motion\n",
    "    refined = cv2.dilate(refined, kernel_dilate, iterations=1)\n",
    "    \n",
    "    # 2. Filter by area\n",
    "    contours, _ = cv2.findContours(refined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Create new mask with only valid contours\n",
    "    filtered_mask = np.zeros_like(refined)\n",
    "    \n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if CONFIG['min_motion_area'] < area < CONFIG['max_motion_area']:\n",
    "            cv2.drawContours(filtered_mask, [contour], -1, 255, -1)\n",
    "    \n",
    "    return filtered_mask, contours\n",
    "\n",
    "def apply_temporal_smoothing(mask, mask_history):\n",
    "    \"\"\"Smooth mask over time to reduce flicker\"\"\"\n",
    "    mask_history.append(mask.astype(float) / 255.0)\n",
    "    \n",
    "    # Average recent masks\n",
    "    avg_mask = np.mean(mask_history, axis=0)\n",
    "    \n",
    "    # Threshold back to binary\n",
    "    smoothed = (avg_mask > 0.3).astype(np.uint8) * 255\n",
    "    \n",
    "    return smoothed\n",
    "\n",
    "def detect_roi_auto(cap, bg_subtractor):\n",
    "    \"\"\"Automatically detect driver area by finding motion region\"\"\"\n",
    "    print(\"üîç Auto-detecting driver region...\")\n",
    "    \n",
    "    # Read first frame to get dimensions\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"‚ö†Ô∏è Could not read frame for ROI detection\")\n",
    "        return None\n",
    "    \n",
    "    motion_accumulator = np.zeros(first_frame.shape[:2], dtype=np.float32)\n",
    "    \n",
    "    # Process first frame\n",
    "    fg_mask = bg_subtractor.apply(first_frame)\n",
    "    motion_accumulator += fg_mask.astype(float) / 255.0\n",
    "    \n",
    "    # Sample more frames to find consistent motion area\n",
    "    for _ in range(49):  # 49 more frames to total 50\n",
    "        ret, sample_frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        fg_mask = bg_subtractor.apply(sample_frame)\n",
    "        motion_accumulator += fg_mask.astype(float) / 255.0\n",
    "    \n",
    "    # Find bounding box of motion\n",
    "    motion_map = (motion_accumulator > 10).astype(np.uint8) * 255\n",
    "    contours, _ = cv2.findContours(motion_map, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if contours:\n",
    "        # Get bounding box of largest motion area\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "        \n",
    "        # Add padding\n",
    "        pad_x = int(w * CONFIG['roi_padding'])\n",
    "        pad_y = int(h * CONFIG['roi_padding'])\n",
    "        \n",
    "        x = max(0, x - pad_x)\n",
    "        y = max(0, y - pad_y)\n",
    "        w = min(first_frame.shape[1] - x, w + 2*pad_x)\n",
    "        h = min(first_frame.shape[0] - y, h + 2*pad_y)\n",
    "        \n",
    "        print(f\"‚úÖ ROI detected: ({x}, {y}, {w}, {h})\")\n",
    "        return (x, y, w, h)\n",
    "    \n",
    "    print(\"‚ö†Ô∏è Could not auto-detect ROI, using full frame\")\n",
    "    return None\n",
    "\n",
    "print(\"‚úÖ Utility functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b57e31c-80e4-4916-bcae-cae1f7cdc92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Visualizer class defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 4: Visualization Class\n",
    "# ============================================================================\n",
    "\n",
    "class DriverMotionVisualizer:\n",
    "    \"\"\"Elegant visualization of driver motion\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.motion_trails = deque(maxlen=CONFIG['trail_length'])\n",
    "        self.contour_history = deque(maxlen=5)\n",
    "    \n",
    "    def create_overlay(self, frame, mask):\n",
    "        \"\"\"Create overlay visualization\"\"\"\n",
    "        overlay = frame.copy()\n",
    "        \n",
    "        # Apply colored mask\n",
    "        colored_mask = np.zeros_like(frame)\n",
    "        colored_mask[mask > 0] = CONFIG['mask_color']\n",
    "        \n",
    "        # Blend with original\n",
    "        result = cv2.addWeighted(frame, 1.0, colored_mask, CONFIG['overlay_alpha'], 0)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def create_heatmap(self, frame, mask):\n",
    "        \"\"\"Create heatmap visualization\"\"\"\n",
    "        # Apply colormap to mask\n",
    "        heatmap = cv2.applyColorMap(mask, cv2.COLORMAP_JET)\n",
    "        \n",
    "        # Blend with original\n",
    "        result = cv2.addWeighted(frame, 0.6, heatmap, 0.4, 0)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def create_side_by_side(self, frame, mask):\n",
    "        \"\"\"Create side-by-side comparison\"\"\"\n",
    "        # Convert mask to 3-channel\n",
    "        mask_3ch = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        # Stack horizontally\n",
    "        result = np.hstack([frame, mask_3ch])\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def draw_contours(self, frame, contours):\n",
    "        \"\"\"Draw motion contours\"\"\"\n",
    "        if CONFIG['show_contours'] and contours:\n",
    "            valid_contours = [c for c in contours if cv2.contourArea(c) > CONFIG['min_motion_area']]\n",
    "            cv2.drawContours(frame, valid_contours, -1, \n",
    "                           CONFIG['contour_color'], CONFIG['contour_thickness'])\n",
    "    \n",
    "    def draw_trails(self, frame, contours):\n",
    "        \"\"\"Draw motion trails\"\"\"\n",
    "        if not CONFIG['show_trails']:\n",
    "            return\n",
    "        \n",
    "        # Get centroids of motion regions\n",
    "        centroids = []\n",
    "        for contour in contours:\n",
    "            if cv2.contourArea(contour) > CONFIG['min_motion_area']:\n",
    "                M = cv2.moments(contour)\n",
    "                if M['m00'] > 0:\n",
    "                    cx = int(M['m10'] / M['m00'])\n",
    "                    cy = int(M['m01'] / M['m00'])\n",
    "                    centroids.append((cx, cy))\n",
    "        \n",
    "        if centroids:\n",
    "            self.motion_trails.append(centroids)\n",
    "        \n",
    "        # Draw trails\n",
    "        for i, trail_points in enumerate(self.motion_trails):\n",
    "            alpha = (i + 1) / len(self.motion_trails)\n",
    "            for point in trail_points:\n",
    "                radius = max(2, int(5 * alpha))\n",
    "                color = tuple(int(c * alpha) for c in CONFIG['trail_color'])\n",
    "                cv2.circle(frame, point, radius, color, -1)\n",
    "    \n",
    "    def add_info_panel(self, frame, frame_num, total_frames, motion_percentage):\n",
    "        \"\"\"Add information overlay\"\"\"\n",
    "        h, w = frame.shape[:2]\n",
    "        \n",
    "        # Semi-transparent panel\n",
    "        panel = frame.copy()\n",
    "        cv2.rectangle(panel, (10, h - 120), (400, h - 10), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(panel, 0.5, frame, 0.5, 0, frame)\n",
    "        \n",
    "        # Text info\n",
    "        info_lines = [\n",
    "            f\"Frame: {frame_num}/{total_frames}\",\n",
    "            f\"Progress: {(frame_num/total_frames)*100:.1f}%\",\n",
    "            f\"Motion: {motion_percentage:.1f}%\",\n",
    "        ]\n",
    "        \n",
    "        y_offset = h - 95\n",
    "        for line in info_lines:\n",
    "            cv2.putText(frame, line, (20, y_offset),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "            y_offset += 30\n",
    "    \n",
    "    def visualize(self, frame, mask, contours, frame_num, total_frames):\n",
    "        \"\"\"Create final visualization\"\"\"\n",
    "        # Calculate motion percentage\n",
    "        motion_pixels = np.sum(mask > 0)\n",
    "        total_pixels = mask.shape[0] * mask.shape[1]\n",
    "        motion_percentage = (motion_pixels / total_pixels) * 100\n",
    "        \n",
    "        # Create visualization based on mode\n",
    "        if CONFIG['output_mode'] == 'mask':\n",
    "            result = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "        elif CONFIG['output_mode'] == 'overlay':\n",
    "            result = self.create_overlay(frame, mask)\n",
    "            self.draw_contours(result, contours)\n",
    "            self.draw_trails(result, contours)\n",
    "        elif CONFIG['output_mode'] == 'heatmap':\n",
    "            result = self.create_heatmap(frame, mask)\n",
    "        elif CONFIG['output_mode'] == 'side_by_side':\n",
    "            result = self.create_side_by_side(frame, mask)\n",
    "        else:\n",
    "            result = frame\n",
    "        \n",
    "        # Add info panel\n",
    "        self.add_info_panel(result, frame_num, total_frames, motion_percentage)\n",
    "        \n",
    "        return result\n",
    "\n",
    "print(\"‚úÖ Visualizer class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "883eef7d-4670-49df-981b-20d9d3a60793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Main processing function defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 5: Main Processing Function\n",
    "# ============================================================================\n",
    "\n",
    "def process_driver_onboard(input_video_path, output_video_path):\n",
    "    \"\"\"\n",
    "    Professional driver motion masking system\n",
    "    \"\"\"\n",
    "    global cap  # For ROI auto-detection\n",
    "    \n",
    "    # 1. Open video\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"‚ùå Error: Could not open video: {input_video_path}\")\n",
    "        return False\n",
    "    \n",
    "    # 2. Get video properties\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    if frame_width == 0 or frame_height == 0:\n",
    "        print(\"‚ùå Error: Invalid video dimensions\")\n",
    "        cap.release()\n",
    "        return False\n",
    "    \n",
    "    print(f\"\\nüìπ Video Properties:\")\n",
    "    print(f\"   Resolution: {frame_width}x{frame_height}\")\n",
    "    print(f\"   FPS: {fps}\")\n",
    "    print(f\"   Total frames: {total_frames}\")\n",
    "    print(f\"   Duration: {total_frames/fps:.1f}s\")\n",
    "    \n",
    "    # 3. Initialize background subtractor\n",
    "    bg_subtractor = cv2.createBackgroundSubtractorMOG2(\n",
    "        history=CONFIG['bg_history'],\n",
    "        varThreshold=CONFIG['bg_var_threshold'],\n",
    "        detectShadows=CONFIG['detect_shadows']\n",
    "    )\n",
    "    \n",
    "    # 4. Auto-detect ROI if enabled\n",
    "    roi = None\n",
    "    if CONFIG['use_roi'] and CONFIG['roi_coords'] is None:\n",
    "        roi = detect_roi_auto(cap, bg_subtractor)\n",
    "        CONFIG['roi_coords'] = roi\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # Reset to beginning\n",
    "    elif CONFIG['use_roi']:\n",
    "        roi = CONFIG['roi_coords']\n",
    "    \n",
    "    # 5. Setup output video\n",
    "    output_width = frame_width\n",
    "    output_height = frame_height\n",
    "    \n",
    "    if CONFIG['output_mode'] == 'side_by_side':\n",
    "        output_width = frame_width * 2\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*CONFIG['output_codec'])\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (output_width, output_height))\n",
    "    \n",
    "    print(f\"\\n‚úÖ Output: {output_video_path}\")\n",
    "    print(f\"   Mode: {CONFIG['output_mode']}\")\n",
    "    print(f\"   ROI: {'Enabled' if roi else 'Disabled'}\")\n",
    "    \n",
    "    # 6. Initialize systems\n",
    "    visualizer = DriverMotionVisualizer()\n",
    "    mask_history = deque(maxlen=CONFIG['smooth_window'])\n",
    "    \n",
    "    print(f\"\\nüöÄ Processing video...\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"üí° Note: Preview disabled (use opencv-python instead of opencv-python-headless for preview)\")\n",
    "    \n",
    "    frame_count = 0\n",
    "    \n",
    "    # 7. Process frame by frame\n",
    "    try:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Preprocess\n",
    "            processed = preprocess_frame(frame)\n",
    "            \n",
    "            # Apply ROI if set\n",
    "            process_region = processed\n",
    "            if roi:\n",
    "                x, y, w, h = roi\n",
    "                process_region = processed[y:y+h, x:x+w]\n",
    "            \n",
    "            # Background subtraction\n",
    "            fg_mask = bg_subtractor.apply(\n",
    "                process_region, \n",
    "                learningRate=CONFIG['learning_rate']\n",
    "            )\n",
    "            \n",
    "            # Refine mask\n",
    "            refined_mask, contours = refine_mask(fg_mask)\n",
    "            \n",
    "            # Temporal smoothing\n",
    "            if CONFIG['temporal_smoothing']:\n",
    "                refined_mask = apply_temporal_smoothing(refined_mask, mask_history)\n",
    "            \n",
    "            # Restore full frame size if ROI was used\n",
    "            if roi:\n",
    "                full_mask = np.zeros((frame_height, frame_width), dtype=np.uint8)\n",
    "                full_mask[y:y+h, x:x+w] = refined_mask\n",
    "                refined_mask = full_mask\n",
    "            \n",
    "            # Visualize\n",
    "            output_frame = visualizer.visualize(\n",
    "                frame, refined_mask, contours, \n",
    "                frame_count + 1, total_frames\n",
    "            )\n",
    "            \n",
    "            # Write frame\n",
    "            out.write(output_frame)\n",
    "            \n",
    "            # Show preview (only if OpenCV has GUI support)\n",
    "            if CONFIG['show_preview']:\n",
    "                try:\n",
    "                    preview = cv2.resize(output_frame, None, \n",
    "                                       fx=CONFIG['preview_scale'], \n",
    "                                       fy=CONFIG['preview_scale'])\n",
    "                    cv2.imshow('F1 Driver Motion Tracker', preview)\n",
    "                    \n",
    "                    key = cv2.waitKey(1) & 0xFF\n",
    "                    if key == ord('q'):\n",
    "                        print(\"\\n‚èπÔ∏è Stopped by user\")\n",
    "                        break\n",
    "                    elif key == ord('s'):\n",
    "                        cv2.imwrite(f'frame_{frame_count}.jpg', output_frame)\n",
    "                        print(f\"üíæ Saved frame_{frame_count}.jpg\")\n",
    "                except cv2.error:\n",
    "                    # GUI not available, disable preview\n",
    "                    CONFIG['show_preview'] = False\n",
    "                    print(\"‚ö†Ô∏è Preview disabled (OpenCV GUI not available)\")\n",
    "            \n",
    "            # Save debug frames\n",
    "            if CONFIG['save_debug_frames'] and frame_count % CONFIG['debug_interval'] == 0:\n",
    "                cv2.imwrite(f'debug_frame_{frame_count:05d}.jpg', output_frame)\n",
    "            \n",
    "            # Progress\n",
    "            frame_count += 1\n",
    "            if frame_count % 30 == 0:\n",
    "                progress = (frame_count / total_frames) * 100\n",
    "                print(f\"   Progress: {progress:.1f}% | Frame: {frame_count}/{total_frames}\")\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚èπÔ∏è Interrupted by user\")\n",
    "    \n",
    "    finally:\n",
    "        # 8. Cleanup\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        try:\n",
    "            cv2.destroyAllWindows()\n",
    "        except:\n",
    "            pass  # Ignore if GUI not available\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"‚úÖ Processing complete!\")\n",
    "    print(f\"   Processed {frame_count} frames\")\n",
    "    print(f\"   Output saved: {output_video_path}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return True\n",
    "\n",
    "print(\"‚úÖ Main processing function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb85275c-efb5-4083-9466-de3eea12810a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üèÅ F1 DRIVER ONBOARD MOTION TRACKER V2.0\n",
      "   Professional driver motion masking system\n",
      "======================================================================\n",
      "\n",
      "‚öôÔ∏è QUICK CONFIG PRESETS:\n",
      "   1. High Quality (best results, slower)\n",
      "   2. Balanced (good quality, moderate speed)\n",
      "   3. Fast Preview (lower quality, faster)\n",
      "   4. Custom (use CONFIG settings)\n",
      "‚úÖ Using CUSTOM CONFIG settings\n",
      "\n",
      "üé® VISUALIZATION MODES:\n",
      "   1. Overlay (green motion overlay)\n",
      "   2. Heatmap (thermal-style visualization)\n",
      "   3. Side-by-Side (original + mask)\n",
      "   4. Mask Only (black & white)\n",
      "‚úÖ Using HEATMAP mode\n",
      "\n",
      "üìÇ Select F1 onboard video...\n",
      "\n",
      "üìπ Input: C:/Users/wadhw/OneDrive/Desktop/FrameShift/yuki.mp4\n",
      "üíæ Output: yuki_motion_tracked_1.mp4\n",
      "\n",
      "üìπ Video Properties:\n",
      "   Resolution: 1920x1080\n",
      "   FPS: 30\n",
      "   Total frames: 388\n",
      "   Duration: 12.9s\n",
      "üîç Auto-detecting driver region...\n",
      "‚úÖ ROI detected: (0, 144, 1920, 936)\n",
      "\n",
      "‚úÖ Output: yuki_motion_tracked_1.mp4\n",
      "   Mode: heatmap\n",
      "   ROI: Enabled\n",
      "\n",
      "üöÄ Processing video...\n",
      "======================================================================\n",
      "üí° Note: Preview disabled (use opencv-python instead of opencv-python-headless for preview)\n",
      "   Progress: 7.7% | Frame: 30/388\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELL 6: Main Execution (Run this to start)\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üèÅ F1 DRIVER ONBOARD MOTION TRACKER V2.0\")\n",
    "    print(\"   Professional driver motion masking system\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    # Configuration options\n",
    "    print(\"‚öôÔ∏è QUICK CONFIG PRESETS:\")\n",
    "    print(\"   1. High Quality (best results, slower)\")\n",
    "    print(\"   2. Balanced (good quality, moderate speed)\")\n",
    "    print(\"   3. Fast Preview (lower quality, faster)\")\n",
    "    print(\"   4. Custom (use CONFIG settings)\")\n",
    "    \n",
    "    preset = input(\"\\nSelect preset (1-4) or press Enter for default [2]: \").strip()\n",
    "    \n",
    "    if preset == \"1\":\n",
    "        # High Quality\n",
    "        CONFIG['denoise_strength'] = 7\n",
    "        CONFIG['morphology_iterations'] = 3\n",
    "        CONFIG['temporal_smoothing'] = True\n",
    "        CONFIG['smooth_window'] = 7\n",
    "        print(\"‚úÖ Using HIGH QUALITY preset\")\n",
    "    elif preset == \"3\":\n",
    "        # Fast Preview\n",
    "        CONFIG['denoise_strength'] = 3\n",
    "        CONFIG['morphology_iterations'] = 1\n",
    "        CONFIG['temporal_smoothing'] = False\n",
    "        CONFIG['learning_rate'] = 0.005\n",
    "        print(\"‚úÖ Using FAST PREVIEW preset\")\n",
    "    elif preset == \"4\":\n",
    "        print(\"‚úÖ Using CUSTOM CONFIG settings\")\n",
    "    else:\n",
    "        # Balanced (default)\n",
    "        print(\"‚úÖ Using BALANCED preset\")\n",
    "    \n",
    "    # Select visualization mode\n",
    "    print(\"\\nüé® VISUALIZATION MODES:\")\n",
    "    print(\"   1. Overlay (green motion overlay)\")\n",
    "    print(\"   2. Heatmap (thermal-style visualization)\")\n",
    "    print(\"   3. Side-by-Side (original + mask)\")\n",
    "    print(\"   4. Mask Only (black & white)\")\n",
    "    \n",
    "    viz_mode = input(\"\\nSelect mode (1-4) or press Enter for default [1]: \").strip()\n",
    "    \n",
    "    if viz_mode == \"2\":\n",
    "        CONFIG['output_mode'] = 'heatmap'\n",
    "    elif viz_mode == \"3\":\n",
    "        CONFIG['output_mode'] = 'side_by_side'\n",
    "    elif viz_mode == \"4\":\n",
    "        CONFIG['output_mode'] = 'mask'\n",
    "    else:\n",
    "        CONFIG['output_mode'] = 'overlay'\n",
    "    \n",
    "    print(f\"‚úÖ Using {CONFIG['output_mode'].upper()} mode\\n\")\n",
    "    \n",
    "    # Get video file\n",
    "    use_gui = input(\"üìÇ Use file dialog to select video? (y/n) [y]: \").strip().lower()\n",
    "    \n",
    "    if use_gui != 'n':\n",
    "        INPUT_VIDEO = select_video_gui()\n",
    "        if not INPUT_VIDEO:\n",
    "            print(\"‚ùå No video selected. Exiting.\")\n",
    "            sys.exit(1)\n",
    "    else:\n",
    "        INPUT_VIDEO = input(\"Enter video path: \").strip().strip('\"')\n",
    "    \n",
    "    # Generate output filename\n",
    "    import os\n",
    "    base_name = os.path.splitext(os.path.basename(INPUT_VIDEO))[0]\n",
    "    OUTPUT_VIDEO = f\"{base_name}_motion_tracked_1.mp4\"\n",
    "    \n",
    "    print(f\"\\nüìπ Input: {INPUT_VIDEO}\")\n",
    "    print(f\"üíæ Output: {OUTPUT_VIDEO}\")\n",
    "    \n",
    "    # Confirm\n",
    "    proceed = input(\"\\n‚ñ∂Ô∏è Start processing? (y/n) [y]: \").strip().lower()\n",
    "    \n",
    "    if proceed == 'n':\n",
    "        print(\"‚ùå Processing cancelled.\")\n",
    "        sys.exit(0)\n",
    "    \n",
    "    # Process video\n",
    "    try:\n",
    "        success = process_driver_onboard(INPUT_VIDEO, OUTPUT_VIDEO)\n",
    "        \n",
    "        if success:\n",
    "            print(\"\\nüéâ SUCCESS! Your driver motion tracking video is ready!\")\n",
    "            print(f\"   Location: {OUTPUT_VIDEO}\")\n",
    "            print(\"\\nüí° Tips:\")\n",
    "            print(\"   ‚Ä¢ Try different visualization modes for better results\")\n",
    "            print(\"   ‚Ä¢ Adjust CONFIG settings for fine-tuning\")\n",
    "            print(\"   ‚Ä¢ Use ROI to focus on driver area only\")\n",
    "        else:\n",
    "            print(\"\\n‚ùå Processing failed. Check error messages above.\")\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\n‚ùå ERROR: Video file not found: {INPUT_VIDEO}\")\n",
    "        print(\"   Please check the file path and try again.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå An unexpected error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üèÅ F1 DRIVER ONBOARD MOTION TRACKER - Session Complete\")\n",
    "    print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
