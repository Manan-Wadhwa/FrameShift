{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2b2ef73-e96b-49ee-9763-c41eaafe00b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÅ F1 Race Position Tracker V1.0 Ready!\n",
      "   ‚Ä¢ Car Detection & Tracking\n",
      "   ‚Ä¢ Overtake Detection\n",
      "   ‚Ä¢ Position Analysis\n",
      "   ‚Ä¢ Race Timeline Generation\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# F1 RACE POSITION TRACKER V1.0\n",
    "# Detect overtakes and track car positions in race footage\n",
    "# ============================================================================\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, deque\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import json\n",
    "from datetime import timedelta\n",
    "\n",
    "print(\"üèÅ F1 Race Position Tracker V1.0 Ready!\")\n",
    "print(\"   ‚Ä¢ Car Detection & Tracking\")\n",
    "print(\"   ‚Ä¢ Overtake Detection\")\n",
    "print(\"   ‚Ä¢ Position Analysis\")\n",
    "print(\"   ‚Ä¢ Race Timeline Generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96e6f237-3f47-4dcb-9e74-93ecc8c9d25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Current Configuration:\n",
      "   video_path: None\n",
      "   use_webcam: False\n",
      "   min_car_area: 500\n",
      "   max_car_area: 50000\n",
      "   detection_roi: None\n",
      "   max_track_age: 30\n",
      "   min_track_confidence: 5\n",
      "   position_threshold: 50\n",
      "   overtake_cooldown: 60\n",
      "   lateral_threshold: 30\n",
      "   overtake_duration: 10\n",
      "   show_trails: True\n",
      "   trail_length: 30\n",
      "   show_speed_estimate: True\n",
      "   output_video: True\n",
      "   output_path: f1_race_analysis.mp4\n",
      "   save_telemetry: True\n",
      "   telemetry_path: race_telemetry.json\n",
      "   generate_timeline: True\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 1: Configuration\n",
    "# ============================================================================\n",
    "\n",
    "CONFIG = {\n",
    "    # Video input\n",
    "    'video_path': None,  # Set to video path or None for file dialog\n",
    "    'use_webcam': False,  # True to use webcam for testing\n",
    "    \n",
    "    # Detection settings\n",
    "    'min_car_area': 500,  # Minimum pixels for car detection\n",
    "    'max_car_area': 50000,  # Maximum pixels for car detection\n",
    "    'detection_roi': None,  # (x, y, w, h) or None for full frame\n",
    "    \n",
    "    # Tracking settings\n",
    "    'max_track_age': 30,  # Frames before track is lost\n",
    "    'min_track_confidence': 5,  # Minimum frames to confirm track\n",
    "    'position_threshold': 50,  # Pixels to consider position change\n",
    "    \n",
    "    # Overtake detection\n",
    "    'overtake_cooldown': 60,  # Frames between same overtake events\n",
    "    'lateral_threshold': 30,  # Horizontal movement for overtake\n",
    "    'overtake_duration': 10,  # Frames to confirm overtake\n",
    "    \n",
    "    # Visualization\n",
    "    'show_trails': True,  # Show car movement trails\n",
    "    'trail_length': 30,  # Number of points in trail\n",
    "    'show_speed_estimate': True,  # Show relative speed\n",
    "    'output_video': True,  # Save annotated video\n",
    "    'output_path': 'f1_race_analysis.mp4',\n",
    "    \n",
    "    # Analysis\n",
    "    'save_telemetry': True,  # Save position data to JSON\n",
    "    'telemetry_path': 'race_telemetry.json',\n",
    "    'generate_timeline': True,  # Create overtake timeline\n",
    "}\n",
    "\n",
    "print(\"üìã Current Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f36b2169-f7b6-4592-959d-8336bf88618e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data structures initialized\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 2: Data Structures\n",
    "# ============================================================================\n",
    "\n",
    "@dataclass\n",
    "class CarTrack:\n",
    "    \"\"\"Represents a tracked car\"\"\"\n",
    "    id: int\n",
    "    name: str\n",
    "    color: Tuple[int, int, int]\n",
    "    positions: deque  # Recent positions\n",
    "    bboxes: deque  # Recent bounding boxes\n",
    "    last_seen: int  # Frame number\n",
    "    confidence: int  # Tracking confidence\n",
    "    total_frames: int  # Total frames tracked\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if not isinstance(self.positions, deque):\n",
    "            self.positions = deque(maxlen=CONFIG['trail_length'])\n",
    "        if not isinstance(self.bboxes, deque):\n",
    "            self.bboxes = deque(maxlen=10)\n",
    "    \n",
    "    def update(self, position, bbox, frame_num):\n",
    "        \"\"\"Update track with new detection\"\"\"\n",
    "        self.positions.append(position)\n",
    "        self.bboxes.append(bbox)\n",
    "        self.last_seen = frame_num\n",
    "        self.confidence = min(self.confidence + 1, 100)\n",
    "        self.total_frames += 1\n",
    "    \n",
    "    def get_velocity(self):\n",
    "        \"\"\"Estimate velocity from recent positions\"\"\"\n",
    "        if len(self.positions) < 2:\n",
    "            return (0, 0)\n",
    "        \n",
    "        recent = list(self.positions)[-5:]\n",
    "        dx = recent[-1][0] - recent[0][0]\n",
    "        dy = recent[-1][1] - recent[0][1]\n",
    "        return (dx / len(recent), dy / len(recent))\n",
    "    \n",
    "    def get_current_position(self):\n",
    "        \"\"\"Get most recent position\"\"\"\n",
    "        return self.positions[-1] if self.positions else None\n",
    "\n",
    "@dataclass\n",
    "class OvertakeEvent:\n",
    "    \"\"\"Represents an overtake\"\"\"\n",
    "    frame: int\n",
    "    timestamp: float\n",
    "    overtaking_car: str\n",
    "    overtaken_car: str\n",
    "    position_before: Tuple[int, int]\n",
    "    position_after: Tuple[int, int]\n",
    "    confidence: float\n",
    "\n",
    "class RaceTracker:\n",
    "    \"\"\"Main tracking system\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tracks: Dict[int, CarTrack] = {}\n",
    "        self.next_id = 0\n",
    "        self.frame_count = 0\n",
    "        self.overtakes: List[OvertakeEvent] = []\n",
    "        self.last_overtake = defaultdict(int)  # Cooldown tracking\n",
    "        \n",
    "        # Car colors for visualization (expand as needed)\n",
    "        self.car_colors = [\n",
    "            (255, 0, 0),    # Red\n",
    "            (0, 0, 255),    # Blue\n",
    "            (0, 255, 0),    # Green\n",
    "            (255, 255, 0),  # Yellow\n",
    "            (255, 0, 255),  # Magenta\n",
    "            (0, 255, 255),  # Cyan\n",
    "            (255, 128, 0),  # Orange\n",
    "            (128, 0, 255),  # Purple\n",
    "        ]\n",
    "        \n",
    "        # Telemetry data\n",
    "        self.telemetry = defaultdict(list)\n",
    "    \n",
    "    def create_track(self, position, bbox):\n",
    "        \"\"\"Create new car track\"\"\"\n",
    "        track_id = self.next_id\n",
    "        color = self.car_colors[track_id % len(self.car_colors)]\n",
    "        \n",
    "        track = CarTrack(\n",
    "            id=track_id,\n",
    "            name=f\"Car {track_id + 1}\",\n",
    "            color=color,\n",
    "            positions=deque(maxlen=CONFIG['trail_length']),\n",
    "            bboxes=deque(maxlen=10),\n",
    "            last_seen=self.frame_count,\n",
    "            confidence=1,\n",
    "            total_frames=0\n",
    "        )\n",
    "        \n",
    "        track.update(position, bbox, self.frame_count)\n",
    "        self.tracks[track_id] = track\n",
    "        self.next_id += 1\n",
    "        \n",
    "        return track_id\n",
    "    \n",
    "    def update_tracks(self, detections):\n",
    "        \"\"\"Update all tracks with new detections\"\"\"\n",
    "        self.frame_count += 1\n",
    "        \n",
    "        # Match detections to existing tracks\n",
    "        matched_tracks = set()\n",
    "        matched_detections = set()\n",
    "        \n",
    "        for track_id, track in self.tracks.items():\n",
    "            if track.last_seen < self.frame_count - CONFIG['max_track_age']:\n",
    "                continue\n",
    "            \n",
    "            best_match = None\n",
    "            best_distance = float('inf')\n",
    "            \n",
    "            last_pos = track.get_current_position()\n",
    "            if last_pos is None:\n",
    "                continue\n",
    "            \n",
    "            for i, (position, bbox) in enumerate(detections):\n",
    "                if i in matched_detections:\n",
    "                    continue\n",
    "                \n",
    "                distance = np.linalg.norm(np.array(position) - np.array(last_pos))\n",
    "                \n",
    "                if distance < best_distance and distance < 100:  # Max matching distance\n",
    "                    best_distance = distance\n",
    "                    best_match = i\n",
    "            \n",
    "            if best_match is not None:\n",
    "                track.update(detections[best_match][0], detections[best_match][1], self.frame_count)\n",
    "                matched_tracks.add(track_id)\n",
    "                matched_detections.add(best_match)\n",
    "        \n",
    "        # Create new tracks for unmatched detections\n",
    "        for i, (position, bbox) in enumerate(detections):\n",
    "            if i not in matched_detections:\n",
    "                self.create_track(position, bbox)\n",
    "        \n",
    "        # Record telemetry\n",
    "        for track_id, track in self.tracks.items():\n",
    "            if track.last_seen == self.frame_count:\n",
    "                pos = track.get_current_position()\n",
    "                vel = track.get_velocity()\n",
    "                self.telemetry[track.name].append({\n",
    "                    'frame': self.frame_count,\n",
    "                    'position': pos,\n",
    "                    'velocity': vel,\n",
    "                    'bbox': track.bboxes[-1] if track.bboxes else None\n",
    "                })\n",
    "    \n",
    "    def detect_overtakes(self):\n",
    "        \"\"\"Detect overtake events between cars\"\"\"\n",
    "        active_tracks = [t for t in self.tracks.values() \n",
    "                        if t.last_seen >= self.frame_count - 5 and \n",
    "                        t.confidence >= CONFIG['min_track_confidence']]\n",
    "        \n",
    "        if len(active_tracks) < 2:\n",
    "            return\n",
    "        \n",
    "        # Check all pairs of cars\n",
    "        for i, track1 in enumerate(active_tracks):\n",
    "            for track2 in active_tracks[i+1:]:\n",
    "                self._check_overtake(track1, track2)\n",
    "    \n",
    "    def _check_overtake(self, track1, track2):\n",
    "        \"\"\"Check if one car is overtaking another\"\"\"\n",
    "        if len(track1.positions) < 5 or len(track2.positions) < 5:\n",
    "            return\n",
    "        \n",
    "        # Get recent positions\n",
    "        pos1_old = list(track1.positions)[0]\n",
    "        pos1_new = list(track1.positions)[-1]\n",
    "        pos2_old = list(track2.positions)[0]\n",
    "        pos2_new = list(track2.positions)[-1]\n",
    "        \n",
    "        # Check cooldown\n",
    "        overtake_key = f\"{track1.id}-{track2.id}\"\n",
    "        if self.frame_count - self.last_overtake[overtake_key] < CONFIG['overtake_cooldown']:\n",
    "            return\n",
    "        \n",
    "        # Detect position swap (assuming horizontal racing line)\n",
    "        x1_change = pos1_new[0] - pos1_old[0]\n",
    "        x2_change = pos2_new[0] - pos2_old[0]\n",
    "        \n",
    "        # Check if cars crossed positions\n",
    "        was_behind = pos1_old[0] < pos2_old[0]\n",
    "        now_ahead = pos1_new[0] > pos2_new[0]\n",
    "        \n",
    "        lateral_movement = abs(x1_change - x2_change)\n",
    "        \n",
    "        if was_behind and now_ahead and lateral_movement > CONFIG['lateral_threshold']:\n",
    "            # Track1 overtook Track2\n",
    "            overtake = OvertakeEvent(\n",
    "                frame=self.frame_count,\n",
    "                timestamp=self.frame_count / 30.0,  # Assuming 30 fps\n",
    "                overtaking_car=track1.name,\n",
    "                overtaken_car=track2.name,\n",
    "                position_before=pos1_old,\n",
    "                position_after=pos1_new,\n",
    "                confidence=min(track1.confidence, track2.confidence) / 100.0\n",
    "            )\n",
    "            \n",
    "            self.overtakes.append(overtake)\n",
    "            self.last_overtake[overtake_key] = self.frame_count\n",
    "            \n",
    "            print(f\"üèÅ OVERTAKE! {track1.name} passed {track2.name} at frame {self.frame_count}\")\n",
    "\n",
    "print(\"‚úÖ Data structures initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75fad0cd-355c-4a87-96d0-0861612ee53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Car detector initialized\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 3: Car Detection\n",
    "# ============================================================================\n",
    "\n",
    "class CarDetector:\n",
    "    \"\"\"Detect cars in video frames\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Initialize background subtractor\n",
    "        self.bg_subtractor = cv2.createBackgroundSubtractorMOG2(\n",
    "            history=500, \n",
    "            varThreshold=16, \n",
    "            detectShadows=True\n",
    "        )\n",
    "        \n",
    "        # Color ranges for car detection (expand for specific teams)\n",
    "        self.color_ranges = [\n",
    "            # Red (Ferrari, Red Bull)\n",
    "            ((0, 100, 100), (10, 255, 255)),\n",
    "            ((170, 100, 100), (180, 255, 255)),\n",
    "            # Blue (Mercedes, Alpine)\n",
    "            ((100, 100, 100), (130, 255, 255)),\n",
    "            # Silver/Gray\n",
    "            ((0, 0, 100), (180, 50, 200)),\n",
    "        ]\n",
    "    \n",
    "    def detect_by_motion(self, frame):\n",
    "        \"\"\"Detect cars using motion/background subtraction\"\"\"\n",
    "        # Apply background subtraction\n",
    "        fg_mask = self.bg_subtractor.apply(frame)\n",
    "        \n",
    "        # Clean up mask\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "        fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_CLOSE, kernel)\n",
    "        fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        detections = []\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            \n",
    "            if CONFIG['min_car_area'] < area < CONFIG['max_car_area']:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                \n",
    "                # Filter by aspect ratio (cars are wider than tall)\n",
    "                aspect_ratio = w / h if h > 0 else 0\n",
    "                if 0.8 < aspect_ratio < 4.0:\n",
    "                    center = (x + w//2, y + h//2)\n",
    "                    detections.append((center, (x, y, w, h)))\n",
    "        \n",
    "        return detections\n",
    "    \n",
    "    def detect_by_color(self, frame):\n",
    "        \"\"\"Detect cars using color information\"\"\"\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        combined_mask = np.zeros(frame.shape[:2], dtype=np.uint8)\n",
    "        \n",
    "        for lower, upper in self.color_ranges:\n",
    "            mask = cv2.inRange(hsv, np.array(lower), np.array(upper))\n",
    "            combined_mask = cv2.bitwise_or(combined_mask, mask)\n",
    "        \n",
    "        # Clean up\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))\n",
    "        combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_CLOSE, kernel)\n",
    "        \n",
    "        contours, _ = cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        detections = []\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            \n",
    "            if CONFIG['min_car_area'] < area < CONFIG['max_car_area']:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                center = (x + w//2, y + h//2)\n",
    "                detections.append((center, (x, y, w, h)))\n",
    "        \n",
    "        return detections\n",
    "    \n",
    "    def detect(self, frame):\n",
    "        \"\"\"Combine detection methods\"\"\"\n",
    "        motion_detections = self.detect_by_motion(frame)\n",
    "        color_detections = self.detect_by_color(frame)\n",
    "        \n",
    "        # Merge detections (simple union for now)\n",
    "        all_detections = motion_detections + color_detections\n",
    "        \n",
    "        # Remove duplicates (detections close to each other)\n",
    "        unique_detections = []\n",
    "        for det in all_detections:\n",
    "            is_duplicate = False\n",
    "            for unique_det in unique_detections:\n",
    "                distance = np.linalg.norm(np.array(det[0]) - np.array(unique_det[0]))\n",
    "                if distance < 50:  # Merge threshold\n",
    "                    is_duplicate = True\n",
    "                    break\n",
    "            \n",
    "            if not is_duplicate:\n",
    "                unique_detections.append(det)\n",
    "        \n",
    "        return unique_detections\n",
    "\n",
    "print(\"‚úÖ Car detector initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef5eae1a-dae5-4173-808d-9adc7e6c2657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Visualizer initialized\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 4: Visualization\n",
    "# ============================================================================\n",
    "\n",
    "class RaceVisualizer:\n",
    "    \"\"\"Visualize tracking and overtakes\"\"\"\n",
    "    \n",
    "    def __init__(self, tracker):\n",
    "        self.tracker = tracker\n",
    "        self.overtake_flash = {}  # Flash effect for overtakes\n",
    "    \n",
    "    def draw_track(self, frame, track):\n",
    "        \"\"\"Draw single car track\"\"\"\n",
    "        if not track.positions:\n",
    "            return\n",
    "        \n",
    "        # Draw trail\n",
    "        if CONFIG['show_trails'] and len(track.positions) > 1:\n",
    "            points = np.array(list(track.positions), dtype=np.int32)\n",
    "            for i in range(len(points) - 1):\n",
    "                alpha = (i + 1) / len(points)\n",
    "                thickness = max(1, int(3 * alpha))\n",
    "                cv2.line(frame, tuple(points[i]), tuple(points[i+1]), \n",
    "                        track.color, thickness)\n",
    "        \n",
    "        # Draw current position\n",
    "        pos = track.get_current_position()\n",
    "        if pos and track.bboxes:\n",
    "            x, y, w, h = track.bboxes[-1]\n",
    "            \n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), track.color, 2)\n",
    "            \n",
    "            # Draw car name and info\n",
    "            label = track.name\n",
    "            if CONFIG['show_speed_estimate']:\n",
    "                vel = track.get_velocity()\n",
    "                speed = np.linalg.norm(vel)\n",
    "                label += f\" ({speed:.1f})\"\n",
    "            \n",
    "            # Background for text\n",
    "            (text_w, text_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "            cv2.rectangle(frame, (x, y - text_h - 10), (x + text_w + 10, y), \n",
    "                         track.color, -1)\n",
    "            cv2.putText(frame, label, (x + 5, y - 5),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "            \n",
    "            # Draw position marker\n",
    "            cv2.circle(frame, pos, 5, track.color, -1)\n",
    "            cv2.circle(frame, pos, 7, (255, 255, 255), 2)\n",
    "    \n",
    "    def draw_overtake_notification(self, frame, overtake):\n",
    "        \"\"\"Flash overtake notification\"\"\"\n",
    "        if self.tracker.frame_count - overtake.frame < 60:  # Show for 2 seconds\n",
    "            h, w = frame.shape[:2]\n",
    "            \n",
    "            # Create notification box\n",
    "            text = f\"OVERTAKE! {overtake.overtaking_car} > {overtake.overtaken_car}\"\n",
    "            (text_w, text_h), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_BOLD, 1.0, 2)\n",
    "            \n",
    "            box_x = (w - text_w) // 2 - 20\n",
    "            box_y = 50\n",
    "            \n",
    "            # Pulsing effect\n",
    "            alpha = 0.5 + 0.5 * np.sin((self.tracker.frame_count - overtake.frame) * 0.3)\n",
    "            \n",
    "            overlay = frame.copy()\n",
    "            cv2.rectangle(overlay, (box_x, box_y), (box_x + text_w + 40, box_y + text_h + 20),\n",
    "                         (0, 255, 0), -1)\n",
    "            cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0, frame)\n",
    "            \n",
    "            cv2.putText(frame, text, (box_x + 20, box_y + text_h + 10),\n",
    "                       cv2.FONT_HERSHEY_BOLD, 1.0, (255, 255, 255), 2)\n",
    "    \n",
    "    def draw_race_info(self, frame):\n",
    "        \"\"\"Draw race statistics\"\"\"\n",
    "        h, w = frame.shape[:2]\n",
    "        \n",
    "        # Info panel\n",
    "        info_lines = [\n",
    "            f\"Frame: {self.tracker.frame_count}\",\n",
    "            f\"Cars: {len([t for t in self.tracker.tracks.values() if t.confidence > CONFIG['min_track_confidence']])}\",\n",
    "            f\"Overtakes: {len(self.tracker.overtakes)}\",\n",
    "        ]\n",
    "        \n",
    "        y_offset = h - 100\n",
    "        for i, line in enumerate(info_lines):\n",
    "            cv2.putText(frame, line, (20, y_offset + i * 30),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            cv2.putText(frame, line, (20, y_offset + i * 30),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 1)\n",
    "    \n",
    "    def draw_frame(self, frame):\n",
    "        \"\"\"Draw all visualizations\"\"\"\n",
    "        viz_frame = frame.copy()\n",
    "        \n",
    "        # Draw all tracks\n",
    "        for track in self.tracker.tracks.values():\n",
    "            if track.confidence >= CONFIG['min_track_confidence']:\n",
    "                self.draw_track(viz_frame, track)\n",
    "        \n",
    "        # Draw recent overtakes\n",
    "        for overtake in self.tracker.overtakes[-5:]:  # Last 5 overtakes\n",
    "            self.draw_overtake_notification(viz_frame, overtake)\n",
    "        \n",
    "        # Draw info panel\n",
    "        self.draw_race_info(viz_frame)\n",
    "        \n",
    "        return viz_frame\n",
    "\n",
    "print(\"‚úÖ Visualizer initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9e44970-5b36-4e08-a9a1-b991f9ed7480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Select race video...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Video loaded:\n",
      "   Resolution: 1920x1080\n",
      "   FPS: 30\n",
      "   Total frames: 45\n",
      "‚úÖ Output video: f1_race_analysis.mp4\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 5: Load Video\n",
    "# ============================================================================\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "def select_video():\n",
    "    \"\"\"Open file dialog to select video\"\"\"\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    root.attributes('-topmost', True)\n",
    "    \n",
    "    print(\"üìÇ Select race video...\")\n",
    "    video_path = filedialog.askopenfilename(\n",
    "        title=\"Select Race Video\",\n",
    "        filetypes=[\n",
    "            (\"Video files\", \"*.mp4 *.avi *.mov *.mkv\"),\n",
    "            (\"All files\", \"*.*\")\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    root.destroy()\n",
    "    return video_path\n",
    "\n",
    "# Get video source\n",
    "if CONFIG['use_webcam']:\n",
    "    video_source = 0\n",
    "    print(\"üìπ Using webcam\")\n",
    "elif CONFIG['video_path']:\n",
    "    video_source = CONFIG['video_path']\n",
    "    print(f\"üìπ Using video: {CONFIG['video_path']}\")\n",
    "else:\n",
    "    video_source = select_video()\n",
    "    if not video_source:\n",
    "        print(\"‚ùå No video selected\")\n",
    "        raise FileNotFoundError(\"No video selected\")\n",
    "\n",
    "cap = cv2.VideoCapture(video_source)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"‚ùå Failed to open video: {video_source}\")\n",
    "    raise IOError(\"Failed to open video\")\n",
    "\n",
    "# Get video properties\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "print(f\"‚úÖ Video loaded:\")\n",
    "print(f\"   Resolution: {frame_width}x{frame_height}\")\n",
    "print(f\"   FPS: {fps}\")\n",
    "print(f\"   Total frames: {total_frames}\")\n",
    "\n",
    "# Setup output video writer\n",
    "if CONFIG['output_video']:\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(CONFIG['output_path'], fourcc, fps, \n",
    "                          (frame_width, frame_height))\n",
    "    print(f\"‚úÖ Output video: {CONFIG['output_path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53a9629f-3075-4ff2-a0cb-ecc0022597fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üèÅ STARTING RACE ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Press 'q' to stop, 'p' to pause, 's' to save current frame\n",
      "\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1295: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 53\u001b[0m\n\u001b[0;32m     52\u001b[0m display_frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(viz_frame, (\u001b[38;5;241m1280\u001b[39m, \u001b[38;5;241m720\u001b[39m))\n\u001b[1;32m---> 53\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mF1 Race Tracker\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Progress\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 79\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m CONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_video\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     78\u001b[0m         out\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m---> 79\u001b[0m     \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdestroyAllWindows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m70\u001b[39m)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müìä RACE ANALYSIS COMPLETE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1295: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 6: Process Video\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üèÅ STARTING RACE ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nPress 'q' to stop, 'p' to pause, 's' to save current frame\\n\")\n",
    "\n",
    "# Initialize systems\n",
    "tracker = RaceTracker()\n",
    "detector = CarDetector()\n",
    "visualizer = RaceVisualizer(tracker)\n",
    "\n",
    "frame_skip = 1  # Process every Nth frame (1 = process all)\n",
    "paused = False\n",
    "\n",
    "try:\n",
    "    while cap.isOpened():\n",
    "        if not paused:\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            if not ret:\n",
    "                print(\"\\n‚úÖ Video processing complete\")\n",
    "                break\n",
    "            \n",
    "            # Process frame\n",
    "            if tracker.frame_count % frame_skip == 0:\n",
    "                # Apply ROI if configured\n",
    "                process_frame = frame\n",
    "                if CONFIG['detection_roi']:\n",
    "                    x, y, w, h = CONFIG['detection_roi']\n",
    "                    process_frame = frame[y:y+h, x:x+w]\n",
    "                \n",
    "                # Detect cars\n",
    "                detections = detector.detect(process_frame)\n",
    "                \n",
    "                # Update tracks\n",
    "                tracker.update_tracks(detections)\n",
    "                \n",
    "                # Detect overtakes\n",
    "                tracker.detect_overtakes()\n",
    "            \n",
    "            # Visualize\n",
    "            viz_frame = visualizer.draw_frame(frame)\n",
    "            \n",
    "            # Save frame\n",
    "            if CONFIG['output_video']:\n",
    "                out.write(viz_frame)\n",
    "            \n",
    "            # Display\n",
    "            display_frame = cv2.resize(viz_frame, (1280, 720))\n",
    "            cv2.imshow('F1 Race Tracker', display_frame)\n",
    "            \n",
    "            # Progress\n",
    "            if tracker.frame_count % 30 == 0:\n",
    "                progress = (tracker.frame_count / total_frames) * 100 if total_frames > 0 else 0\n",
    "                print(f\"Progress: {progress:.1f}% | Frame: {tracker.frame_count} | Cars: {len(tracker.tracks)} | Overtakes: {len(tracker.overtakes)}\")\n",
    "        \n",
    "        # Handle keyboard\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            print(\"\\n‚èπÔ∏è Stopped by user\")\n",
    "            break\n",
    "        elif key == ord('p'):\n",
    "            paused = not paused\n",
    "            print(\"‚è∏Ô∏è Paused\" if paused else \"‚ñ∂Ô∏è Resumed\")\n",
    "        elif key == ord('s'):\n",
    "            cv2.imwrite(f'frame_{tracker.frame_count}.jpg', viz_frame)\n",
    "            print(f\"üíæ Saved frame_{tracker.frame_count}.jpg\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚èπÔ∏è Interrupted by user\")\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    if CONFIG['output_video']:\n",
    "        out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä RACE ANALYSIS COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08a3080-ea6c-4182-8b4d-2c52efb5aed6",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 7: Generate Reports\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüìà Generating analysis reports...\\n\")\n",
    "\n",
    "# Overtake Timeline\n",
    "if CONFIG['generate_timeline'] and tracker.overtakes:\n",
    "    print(\"üèÅ OVERTAKE TIMELINE:\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for i, overtake in enumerate(tracker.overtakes):\n",
    "        timestamp = timedelta(seconds=overtake.timestamp)\n",
    "        print(f\"{i+1}. [{timestamp}] {overtake.overtaking_car} overtook {overtake.overtaken_car}\")\n",
    "        print(f\"   Confidence: {overtake.confidence:.2f}\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "# Track Statistics\n",
    "print(\"üèéÔ∏è CAR STATISTICS:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for track in sorted(tracker.tracks.values(), key=lambda t: t.total_frames, reverse=True):\n",
    "    if track.confidence >= CONFIG['min_track_confidence']:\n",
    "        print(f\"{track.name}:\")\n",
    "        print(f\"   Frames tracked: {track.total_frames}\")\n",
    "        print(f\"   Confidence: {track.confidence}\")\n",
    "        \n",
    "        if track.positions:\n",
    "            positions = list(track.positions)\n",
    "            total_distance = sum(\n",
    "                np.linalg.norm(np.array(positions[i+1]) - np.array(positions[i]))\n",
    "                for i in range(len(positions) - 1)\n",
    "            )\n",
    "            print(f\"   Distance traveled: {total_distance:.1f} pixels\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Save telemetry\n",
    "if CONFIG['save_telemetry']:\n",
    "    telemetry_data = {\n",
    "        'metadata': {\n",
    "            'total_frames': tracker.frame_count,\n",
    "            'fps': fps,\n",
    "            'resolution': [frame_width, frame_height],\n",
    "        },\n",
    "        'cars': {\n",
    "            name: [\n",
    "                {\n",
    "                    'frame': entry['frame'],\n",
    "                    'position': entry['position'],\n",
    "                    'velocity': entry['velocity']\n",
    "                }\n",
    "                for entry in data\n",
    "            ]\n",
    "            for name, data in tracker.telemetry.items()\n",
    "        },\n",
    "        'overtakes': [\n",
    "            {\n",
    "                'frame': ov.frame,\n",
    "                'timestamp': ov.timestamp,\n",
    "                'overtaking_car': ov.overtaking_car,\n",
    "                'overtaken_car': ov.overtaken_car,\n",
    "                'confidence': ov.confidence\n",
    "            }\n",
    "            for ov in tracker.overtakes\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    with open(CONFIG['telemetry_path'], 'w') as f:\n",
    "        json.dump(telemetry_data, f, indent=2)\n",
    "    \n",
    "    print(f\"üíæ Telemetry saved to: {CONFIG['telemetry_path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36be3a69-f31a-4942-b435-cf49db88d2b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 8: Visualization Plots\n",
    "# ============================================================================\n",
    "\n",
    "if tracker.telemetry:\n",
    "    print(\"\\nüìä Generating position plots...\\n\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "    \n",
    "    # Position over time\n",
    "    ax1 = axes[0]\n",
    "    for car_name, data in tracker.telemetry.items():\n",
    "        frames = [entry['frame'] for entry in data]\n",
    "        positions = [entry['position'][0] for entry in data]  # X position\n",
    "        \n",
    "        if len(frames) > 10:\n",
    "            ax1.plot(frames, positions, label=car_name, linewidth=2)\n",
    "    \n",
    "    ax1.set_xlabel('Frame')\n",
    "    ax1.set_ylabel('X Position (pixels)')\n",
    "    ax1.set_title('Car Positions Over Time')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Mark overtakes\n",
    "    for overtake in tracker.overtakes:\n",
    "        ax1.axvline(x=overtake.frame, color='red', linestyle='--', alpha=0.5)\n",
    "        ax1.text(overtake.frame, ax1.get_ylim()[1], 'üèÅ', \n",
    "                ha='center', va='bottom', fontsize=12)\n",
    "    \n",
    "    # Speed estimates\n",
    "    ax2 = axes[1]\n",
    "    for car_name, data in tracker.telemetry.items():\n",
    "        frames = [entry['frame'] for entry in data]\n",
    "        speeds = [np.linalg.norm(entry['velocity']) for entry in data]\n",
    "        \n",
    "        if len(frames) > 10:\n",
    "            ax2.plot(frames, speeds, label=car_name, linewidth=2)\n",
    "    \n",
    "    ax2.set_xlabel('Frame')\n",
    "    ax2.set_ylabel('Speed (pixels/frame)')\n",
    "    ax2.set_title('Relative Speed Over Time')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('race_analysis_plots.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"üíæ Saved race_analysis_plots.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c374da8-56da-485b-8be4-a327bbeb8cf3",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 9: Usage Guide\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìñ F1 RACE TRACKER - USAGE GUIDE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "üéØ CONFIGURATION TIPS:\n",
    "\n",
    "üìπ VIDEO INPUT:\n",
    "   CONFIG['video_path'] = 'race.mp4'  # Specific video\n",
    "   CONFIG['use_webcam'] = True         # Use webcam for testing\n",
    "\n",
    "üîç DETECTION TUNING:\n",
    "   CONFIG['min_car_area'] = 500        # Smaller for distant cars\n",
    "   CONFIG['max_car_area'] = 50000      # Larger for close-up shots\n",
    "   CONFIG['detection_roi'] = (x,y,w,h) # Focus on specific track area\n",
    "\n",
    "üèÅ OVERTAKE SENSITIVITY:\n",
    "   CONFIG['lateral_threshold'] = 30    # Lower = more sensitive\n",
    "   CONFIG['overtake_cooldown'] = 60    # Prevent duplicate detections\n",
    "\n",
    "üìä OUTPUT OPTIONS:\n",
    "   CONFIG['output_video'] = True       # Save annotated video\n",
    "   CONFIG['save_telemetry'] = True     # Save position data (JSON)\n",
    "   CONFIG['generate_timeline'] = True  # Print overtake events\n",
    "\n",
    "üé® VISUALIZATION:\n",
    "   CONFIG['show_trails'] = True        # Car movement trails\n",
    "   CONFIG['show_speed_estimate'] = True# Speed indicators\n",
    "   CONFIG['trail_length'] = 30         # Trail length in frames\n",
    "\n",
    "üí° BEST PRACTICES:\n",
    "   ‚Ä¢ Use stable camera angles (broadcast views work best)\n",
    "   ‚Ä¢ Avoid rapid camera cuts\n",
    "   ‚Ä¢ Good lighting and contrast helps detection\n",
    "   ‚Ä¢ Set detection_roi to focus on main racing line\n",
    "   ‚Ä¢ Adjust min/max_car_area based on camera distance\n",
    "\n",
    "üîß TROUBLESHOOTING:\n",
    "   ‚Ä¢ Cars not detected? Adjust min_car_area\n",
    "   ‚Ä¢ Too many false detections? Increase min_car_area\n",
    "   ‚Ä¢ Missed overtakes? Lower lateral_threshold\n",
    "   ‚Ä¢ Too many false overtakes? Increase overtake_cooldown\n",
    "\n",
    "üöÄ MODIFY CONFIG IN CELL 1, THEN RUN FROM CELL 5!\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"‚úÖ F1 RACE TRACKER READY!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012b8de7-602b-4631-987c-92c8b0e5318c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# END\n",
    "# ============================================================================\n",
    "# F1 RACE POSITION TRACKER V1.0\n",
    "# Detect overtakes and track car positions in race footage\n",
    "# ============================================================================\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, deque\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import json\n",
    "from datetime import timedelta\n",
    "\n",
    "print(\"üèÅ F1 Race Position Tracker V1.0 Ready!\")\n",
    "print(\"   ‚Ä¢ Car Detection & Tracking\")\n",
    "print(\"   ‚Ä¢ Overtake Detection\")\n",
    "print(\"   ‚Ä¢ Position Analysis\")\n",
    "print(\"   ‚Ä¢ Race Timeline Generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0faca77-9778-493e-b578-f05b6912c10b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 1: Configuration\n",
    "# ============================================================================\n",
    "\n",
    "CONFIG = {\n",
    "    # Video input\n",
    "    'video_path': None,  # Set to video path or None for file dialog\n",
    "    'use_webcam': False,  # True to use webcam for testing\n",
    "    \n",
    "    # Detection settings\n",
    "    'min_car_area': 500,  # Minimum pixels for car detection\n",
    "    'max_car_area': 50000,  # Maximum pixels for car detection\n",
    "    'detection_roi': None,  # (x, y, w, h) or None for full frame\n",
    "    \n",
    "    # Tracking settings\n",
    "    'max_track_age': 30,  # Frames before track is lost\n",
    "    'min_track_confidence': 5,  # Minimum frames to confirm track\n",
    "    'position_threshold': 50,  # Pixels to consider position change\n",
    "    \n",
    "    # Overtake detection\n",
    "    'overtake_cooldown': 60,  # Frames between same overtake events\n",
    "    'lateral_threshold': 30,  # Horizontal movement for overtake\n",
    "    'overtake_duration': 10,  # Frames to confirm overtake\n",
    "    \n",
    "    # Visualization\n",
    "    'show_trails': True,  # Show car movement trails\n",
    "    'trail_length': 30,  # Number of points in trail\n",
    "    'show_speed_estimate': True,  # Show relative speed\n",
    "    'output_video': True,  # Save annotated video\n",
    "    'output_path': 'f1_race_analysis.mp4',\n",
    "    \n",
    "    # Analysis\n",
    "    'save_telemetry': True,  # Save position data to JSON\n",
    "    'telemetry_path': 'race_telemetry.json',\n",
    "    'generate_timeline': True,  # Create overtake timeline\n",
    "}\n",
    "\n",
    "print(\"üìã Current Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3c72a0-2f80-499e-8d63-b53c71f9e656",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 2: Data Structures\n",
    "# ============================================================================\n",
    "\n",
    "@dataclass\n",
    "class CarTrack:\n",
    "    \"\"\"Represents a tracked car\"\"\"\n",
    "    id: int\n",
    "    name: str\n",
    "    color: Tuple[int, int, int]\n",
    "    positions: deque  # Recent positions\n",
    "    bboxes: deque  # Recent bounding boxes\n",
    "    last_seen: int  # Frame number\n",
    "    confidence: int  # Tracking confidence\n",
    "    total_frames: int  # Total frames tracked\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if not isinstance(self.positions, deque):\n",
    "            self.positions = deque(maxlen=CONFIG['trail_length'])\n",
    "        if not isinstance(self.bboxes, deque):\n",
    "            self.bboxes = deque(maxlen=10)\n",
    "    \n",
    "    def update(self, position, bbox, frame_num):\n",
    "        \"\"\"Update track with new detection\"\"\"\n",
    "        self.positions.append(position)\n",
    "        self.bboxes.append(bbox)\n",
    "        self.last_seen = frame_num\n",
    "        self.confidence = min(self.confidence + 1, 100)\n",
    "        self.total_frames += 1\n",
    "    \n",
    "    def get_velocity(self):\n",
    "        \"\"\"Estimate velocity from recent positions\"\"\"\n",
    "        if len(self.positions) < 2:\n",
    "            return (0, 0)\n",
    "        \n",
    "        recent = list(self.positions)[-5:]\n",
    "        dx = recent[-1][0] - recent[0][0]\n",
    "        dy = recent[-1][1] - recent[0][1]\n",
    "        return (dx / len(recent), dy / len(recent))\n",
    "    \n",
    "    def get_current_position(self):\n",
    "        \"\"\"Get most recent position\"\"\"\n",
    "        return self.positions[-1] if self.positions else None\n",
    "\n",
    "@dataclass\n",
    "class OvertakeEvent:\n",
    "    \"\"\"Represents an overtake\"\"\"\n",
    "    frame: int\n",
    "    timestamp: float\n",
    "    overtaking_car: str\n",
    "    overtaken_car: str\n",
    "    position_before: Tuple[int, int]\n",
    "    position_after: Tuple[int, int]\n",
    "    confidence: float\n",
    "\n",
    "class RaceTracker:\n",
    "    \"\"\"Main tracking system\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tracks: Dict[int, CarTrack] = {}\n",
    "        self.next_id = 0\n",
    "        self.frame_count = 0\n",
    "        self.overtakes: List[OvertakeEvent] = []\n",
    "        self.last_overtake = defaultdict(int)  # Cooldown tracking\n",
    "        \n",
    "        # Car colors for visualization (expand as needed)\n",
    "        self.car_colors = [\n",
    "            (255, 0, 0),    # Red\n",
    "            (0, 0, 255),    # Blue\n",
    "            (0, 255, 0),    # Green\n",
    "            (255, 255, 0),  # Yellow\n",
    "            (255, 0, 255),  # Magenta\n",
    "            (0, 255, 255),  # Cyan\n",
    "            (255, 128, 0),  # Orange\n",
    "            (128, 0, 255),  # Purple\n",
    "        ]\n",
    "        \n",
    "        # Telemetry data\n",
    "        self.telemetry = defaultdict(list)\n",
    "    \n",
    "    def create_track(self, position, bbox):\n",
    "        \"\"\"Create new car track\"\"\"\n",
    "        track_id = self.next_id\n",
    "        color = self.car_colors[track_id % len(self.car_colors)]\n",
    "        \n",
    "        track = CarTrack(\n",
    "            id=track_id,\n",
    "            name=f\"Car {track_id + 1}\",\n",
    "            color=color,\n",
    "            positions=deque(maxlen=CONFIG['trail_length']),\n",
    "            bboxes=deque(maxlen=10),\n",
    "            last_seen=self.frame_count,\n",
    "            confidence=1,\n",
    "            total_frames=0\n",
    "        )\n",
    "        \n",
    "        track.update(position, bbox, self.frame_count)\n",
    "        self.tracks[track_id] = track\n",
    "        self.next_id += 1\n",
    "        \n",
    "        return track_id\n",
    "    \n",
    "    def update_tracks(self, detections):\n",
    "        \"\"\"Update all tracks with new detections\"\"\"\n",
    "        self.frame_count += 1\n",
    "        \n",
    "        # Match detections to existing tracks\n",
    "        matched_tracks = set()\n",
    "        matched_detections = set()\n",
    "        \n",
    "        for track_id, track in self.tracks.items():\n",
    "            if track.last_seen < self.frame_count - CONFIG['max_track_age']:\n",
    "                continue\n",
    "            \n",
    "            best_match = None\n",
    "            best_distance = float('inf')\n",
    "            \n",
    "            last_pos = track.get_current_position()\n",
    "            if last_pos is None:\n",
    "                continue\n",
    "            \n",
    "            for i, (position, bbox) in enumerate(detections):\n",
    "                if i in matched_detections:\n",
    "                    continue\n",
    "                \n",
    "                distance = np.linalg.norm(np.array(position) - np.array(last_pos))\n",
    "                \n",
    "                if distance < best_distance and distance < 100:  # Max matching distance\n",
    "                    best_distance = distance\n",
    "                    best_match = i\n",
    "            \n",
    "            if best_match is not None:\n",
    "                track.update(detections[best_match][0], detections[best_match][1], self.frame_count)\n",
    "                matched_tracks.add(track_id)\n",
    "                matched_detections.add(best_match)\n",
    "        \n",
    "        # Create new tracks for unmatched detections\n",
    "        for i, (position, bbox) in enumerate(detections):\n",
    "            if i not in matched_detections:\n",
    "                self.create_track(position, bbox)\n",
    "        \n",
    "        # Record telemetry\n",
    "        for track_id, track in self.tracks.items():\n",
    "            if track.last_seen == self.frame_count:\n",
    "                pos = track.get_current_position()\n",
    "                vel = track.get_velocity()\n",
    "                self.telemetry[track.name].append({\n",
    "                    'frame': self.frame_count,\n",
    "                    'position': pos,\n",
    "                    'velocity': vel,\n",
    "                    'bbox': track.bboxes[-1] if track.bboxes else None\n",
    "                })\n",
    "    \n",
    "    def detect_overtakes(self):\n",
    "        \"\"\"Detect overtake events between cars\"\"\"\n",
    "        active_tracks = [t for t in self.tracks.values() \n",
    "                        if t.last_seen >= self.frame_count - 5 and \n",
    "                        t.confidence >= CONFIG['min_track_confidence']]\n",
    "        \n",
    "        if len(active_tracks) < 2:\n",
    "            return\n",
    "        \n",
    "        # Check all pairs of cars\n",
    "        for i, track1 in enumerate(active_tracks):\n",
    "            for track2 in active_tracks[i+1:]:\n",
    "                self._check_overtake(track1, track2)\n",
    "    \n",
    "    def _check_overtake(self, track1, track2):\n",
    "        \"\"\"Check if one car is overtaking another\"\"\"\n",
    "        if len(track1.positions) < 5 or len(track2.positions) < 5:\n",
    "            return\n",
    "        \n",
    "        # Get recent positions\n",
    "        pos1_old = list(track1.positions)[0]\n",
    "        pos1_new = list(track1.positions)[-1]\n",
    "        pos2_old = list(track2.positions)[0]\n",
    "        pos2_new = list(track2.positions)[-1]\n",
    "        \n",
    "        # Check cooldown\n",
    "        overtake_key = f\"{track1.id}-{track2.id}\"\n",
    "        if self.frame_count - self.last_overtake[overtake_key] < CONFIG['overtake_cooldown']:\n",
    "            return\n",
    "        \n",
    "        # Detect position swap (assuming horizontal racing line)\n",
    "        x1_change = pos1_new[0] - pos1_old[0]\n",
    "        x2_change = pos2_new[0] - pos2_old[0]\n",
    "        \n",
    "        # Check if cars crossed positions\n",
    "        was_behind = pos1_old[0] < pos2_old[0]\n",
    "        now_ahead = pos1_new[0] > pos2_new[0]\n",
    "        \n",
    "        lateral_movement = abs(x1_change - x2_change)\n",
    "        \n",
    "        if was_behind and now_ahead and lateral_movement > CONFIG['lateral_threshold']:\n",
    "            # Track1 overtook Track2\n",
    "            overtake = OvertakeEvent(\n",
    "                frame=self.frame_count,\n",
    "                timestamp=self.frame_count / 30.0,  # Assuming 30 fps\n",
    "                overtaking_car=track1.name,\n",
    "                overtaken_car=track2.name,\n",
    "                position_before=pos1_old,\n",
    "                position_after=pos1_new,\n",
    "                confidence=min(track1.confidence, track2.confidence) / 100.0\n",
    "            )\n",
    "            \n",
    "            self.overtakes.append(overtake)\n",
    "            self.last_overtake[overtake_key] = self.frame_count\n",
    "            \n",
    "            print(f\"üèÅ OVERTAKE! {track1.name} passed {track2.name} at frame {self.frame_count}\")\n",
    "\n",
    "print(\"‚úÖ Data structures initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9af466d-a269-4b94-8483-d7809f3430f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 3: Car Detection\n",
    "# ============================================================================\n",
    "\n",
    "class CarDetector:\n",
    "    \"\"\"Detect cars in video frames\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Initialize background subtractor\n",
    "        self.bg_subtractor = cv2.createBackgroundSubtractorMOG2(\n",
    "            history=500, \n",
    "            varThreshold=16, \n",
    "            detectShadows=True\n",
    "        )\n",
    "        \n",
    "        # Color ranges for car detection (expand for specific teams)\n",
    "        self.color_ranges = [\n",
    "            # Red (Ferrari, Red Bull)\n",
    "            ((0, 100, 100), (10, 255, 255)),\n",
    "            ((170, 100, 100), (180, 255, 255)),\n",
    "            # Blue (Mercedes, Alpine)\n",
    "            ((100, 100, 100), (130, 255, 255)),\n",
    "            # Silver/Gray\n",
    "            ((0, 0, 100), (180, 50, 200)),\n",
    "        ]\n",
    "    \n",
    "    def detect_by_motion(self, frame):\n",
    "        \"\"\"Detect cars using motion/background subtraction\"\"\"\n",
    "        # Apply background subtraction\n",
    "        fg_mask = self.bg_subtractor.apply(frame)\n",
    "        \n",
    "        # Clean up mask\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "        fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_CLOSE, kernel)\n",
    "        fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        detections = []\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            \n",
    "            if CONFIG['min_car_area'] < area < CONFIG['max_car_area']:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                \n",
    "                # Filter by aspect ratio (cars are wider than tall)\n",
    "                aspect_ratio = w / h if h > 0 else 0\n",
    "                if 0.8 < aspect_ratio < 4.0:\n",
    "                    center = (x + w//2, y + h//2)\n",
    "                    detections.append((center, (x, y, w, h)))\n",
    "        \n",
    "        return detections\n",
    "    \n",
    "    def detect_by_color(self, frame):\n",
    "        \"\"\"Detect cars using color information\"\"\"\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        combined_mask = np.zeros(frame.shape[:2], dtype=np.uint8)\n",
    "        \n",
    "        for lower, upper in self.color_ranges:\n",
    "            mask = cv2.inRange(hsv, np.array(lower), np.array(upper))\n",
    "            combined_mask = cv2.bitwise_or(combined_mask, mask)\n",
    "        \n",
    "        # Clean up\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))\n",
    "        combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_CLOSE, kernel)\n",
    "        \n",
    "        contours, _ = cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        detections = []\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            \n",
    "            if CONFIG['min_car_area'] < area < CONFIG['max_car_area']:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                center = (x + w//2, y + h//2)\n",
    "                detections.append((center, (x, y, w, h)))\n",
    "        \n",
    "        return detections\n",
    "    \n",
    "    def detect(self, frame):\n",
    "        \"\"\"Combine detection methods\"\"\"\n",
    "        motion_detections = self.detect_by_motion(frame)\n",
    "        color_detections = self.detect_by_color(frame)\n",
    "        \n",
    "        # Merge detections (simple union for now)\n",
    "        all_detections = motion_detections + color_detections\n",
    "        \n",
    "        # Remove duplicates (detections close to each other)\n",
    "        unique_detections = []\n",
    "        for det in all_detections:\n",
    "            is_duplicate = False\n",
    "            for unique_det in unique_detections:\n",
    "                distance = np.linalg.norm(np.array(det[0]) - np.array(unique_det[0]))\n",
    "                if distance < 50:  # Merge threshold\n",
    "                    is_duplicate = True\n",
    "                    break\n",
    "            \n",
    "            if not is_duplicate:\n",
    "                unique_detections.append(det)\n",
    "        \n",
    "        return unique_detections\n",
    "\n",
    "print(\"‚úÖ Car detector initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c81b207-2ebc-4a64-a0d1-c2122bbfa79c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 4: Visualization\n",
    "# ============================================================================\n",
    "\n",
    "class RaceVisualizer:\n",
    "    \"\"\"Visualize tracking and overtakes\"\"\"\n",
    "    \n",
    "    def __init__(self, tracker):\n",
    "        self.tracker = tracker\n",
    "        self.overtake_flash = {}  # Flash effect for overtakes\n",
    "    \n",
    "    def draw_track(self, frame, track):\n",
    "        \"\"\"Draw single car track\"\"\"\n",
    "        if not track.positions:\n",
    "            return\n",
    "        \n",
    "        # Draw trail\n",
    "        if CONFIG['show_trails'] and len(track.positions) > 1:\n",
    "            points = np.array(list(track.positions), dtype=np.int32)\n",
    "            for i in range(len(points) - 1):\n",
    "                alpha = (i + 1) / len(points)\n",
    "                thickness = max(1, int(3 * alpha))\n",
    "                cv2.line(frame, tuple(points[i]), tuple(points[i+1]), \n",
    "                        track.color, thickness)\n",
    "        \n",
    "        # Draw current position\n",
    "        pos = track.get_current_position()\n",
    "        if pos and track.bboxes:\n",
    "            x, y, w, h = track.bboxes[-1]\n",
    "            \n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), track.color, 2)\n",
    "            \n",
    "            # Draw car name and info\n",
    "            label = track.name\n",
    "            if CONFIG['show_speed_estimate']:\n",
    "                vel = track.get_velocity()\n",
    "                speed = np.linalg.norm(vel)\n",
    "                label += f\" ({speed:.1f})\"\n",
    "            \n",
    "            # Background for text\n",
    "            (text_w, text_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "            cv2.rectangle(frame, (x, y - text_h - 10), (x + text_w + 10, y), \n",
    "                         track.color, -1)\n",
    "            cv2.putText(frame, label, (x + 5, y - 5),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "            \n",
    "            # Draw position marker\n",
    "            cv2.circle(frame, pos, 5, track.color, -1)\n",
    "            cv2.circle(frame, pos, 7, (255, 255, 255), 2)\n",
    "    \n",
    "    def draw_overtake_notification(self, frame, overtake):\n",
    "        \"\"\"Flash overtake notification\"\"\"\n",
    "        if self.tracker.frame_count - overtake.frame < 60:  # Show for 2 seconds\n",
    "            h, w = frame.shape[:2]\n",
    "            \n",
    "            # Create notification box\n",
    "            text = f\"OVERTAKE! {overtake.overtaking_car} > {overtake.overtaken_car}\"\n",
    "            (text_w, text_h), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_BOLD, 1.0, 2)\n",
    "            \n",
    "            box_x = (w - text_w) // 2 - 20\n",
    "            box_y = 50\n",
    "            \n",
    "            # Pulsing effect\n",
    "            alpha = 0.5 + 0.5 * np.sin((self.tracker.frame_count - overtake.frame) * 0.3)\n",
    "            \n",
    "            overlay = frame.copy()\n",
    "            cv2.rectangle(overlay, (box_x, box_y), (box_x + text_w + 40, box_y + text_h + 20),\n",
    "                         (0, 255, 0), -1)\n",
    "            cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0, frame)\n",
    "            \n",
    "            cv2.putText(frame, text, (box_x + 20, box_y + text_h + 10),\n",
    "                       cv2.FONT_HERSHEY_BOLD, 1.0, (255, 255, 255), 2)\n",
    "    \n",
    "    def draw_race_info(self, frame):\n",
    "        \"\"\"Draw race statistics\"\"\"\n",
    "        h, w = frame.shape[:2]\n",
    "        \n",
    "        # Info panel\n",
    "        info_lines = [\n",
    "            f\"Frame: {self.tracker.frame_count}\",\n",
    "            f\"Cars: {len([t for t in self.tracker.tracks.values() if t.confidence > CONFIG['min_track_confidence']])}\",\n",
    "            f\"Overtakes: {len(self.tracker.overtakes)}\",\n",
    "        ]\n",
    "        \n",
    "        y_offset = h - 100\n",
    "        for i, line in enumerate(info_lines):\n",
    "            cv2.putText(frame, line, (20, y_offset + i * 30),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            cv2.putText(frame, line, (20, y_offset + i * 30),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 1)\n",
    "    \n",
    "    def draw_frame(self, frame):\n",
    "        \"\"\"Draw all visualizations\"\"\"\n",
    "        viz_frame = frame.copy()\n",
    "        \n",
    "        # Draw all tracks\n",
    "        for track in self.tracker.tracks.values():\n",
    "            if track.confidence >= CONFIG['min_track_confidence']:\n",
    "                self.draw_track(viz_frame, track)\n",
    "        \n",
    "        # Draw recent overtakes\n",
    "        for overtake in self.tracker.overtakes[-5:]:  # Last 5 overtakes\n",
    "            self.draw_overtake_notification(viz_frame, overtake)\n",
    "        \n",
    "        # Draw info panel\n",
    "        self.draw_race_info(viz_frame)\n",
    "        \n",
    "        return viz_frame\n",
    "\n",
    "print(\"‚úÖ Visualizer initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04abdf6-3c0f-4172-9390-c274d45e0552",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 5: Load Video\n",
    "# ============================================================================\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "def select_video():\n",
    "    \"\"\"Open file dialog to select video\"\"\"\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    root.attributes('-topmost', True)\n",
    "    \n",
    "    print(\"üìÇ Select race video...\")\n",
    "    video_path = filedialog.askopenfilename(\n",
    "        title=\"Select Race Video\",\n",
    "        filetypes=[\n",
    "            (\"Video files\", \"*.mp4 *.avi *.mov *.mkv\"),\n",
    "            (\"All files\", \"*.*\")\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    root.destroy()\n",
    "    return video_path\n",
    "\n",
    "# Get video source\n",
    "if CONFIG['use_webcam']:\n",
    "    video_source = 0\n",
    "    print(\"üìπ Using webcam\")\n",
    "elif CONFIG['video_path']:\n",
    "    video_source = CONFIG['video_path']\n",
    "    print(f\"üìπ Using video: {CONFIG['video_path']}\")\n",
    "else:\n",
    "    video_source = select_video()\n",
    "    if not video_source:\n",
    "        print(\"‚ùå No video selected\")\n",
    "        raise FileNotFoundError(\"No video selected\")\n",
    "\n",
    "cap = cv2.VideoCapture(video_source)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"‚ùå Failed to open video: {video_source}\")\n",
    "    raise IOError(\"Failed to open video\")\n",
    "\n",
    "# Get video properties\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "print(f\"‚úÖ Video loaded:\")\n",
    "print(f\"   Resolution: {frame_width}x{frame_height}\")\n",
    "print(f\"   FPS: {fps}\")\n",
    "print(f\"   Total frames: {total_frames}\")\n",
    "\n",
    "# Setup output video writer\n",
    "if CONFIG['output_video']:\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(CONFIG['output_path'], fourcc, fps, \n",
    "                          (frame_width, frame_height))\n",
    "    print(f\"‚úÖ Output video: {CONFIG['output_path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6219a000-d047-4b59-93c6-e69bec1f5871",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 6: Process Video\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üèÅ STARTING RACE ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nPress 'q' to stop, 'p' to pause, 's' to save current frame\\n\")\n",
    "\n",
    "# Initialize systems\n",
    "tracker = RaceTracker()\n",
    "detector = CarDetector()\n",
    "visualizer = RaceVisualizer(tracker)\n",
    "\n",
    "frame_skip = 1  # Process every Nth frame (1 = process all)\n",
    "paused = False\n",
    "\n",
    "try:\n",
    "    while cap.isOpened():\n",
    "        if not paused:\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            if not ret:\n",
    "                print(\"\\n‚úÖ Video processing complete\")\n",
    "                break\n",
    "            \n",
    "            # Process frame\n",
    "            if tracker.frame_count % frame_skip == 0:\n",
    "                # Apply ROI if configured\n",
    "                process_frame = frame\n",
    "                if CONFIG['detection_roi']:\n",
    "                    x, y, w, h = CONFIG['detection_roi']\n",
    "                    process_frame = frame[y:y+h, x:x+w]\n",
    "                \n",
    "                # Detect cars\n",
    "                detections = detector.detect(process_frame)\n",
    "                \n",
    "                # Update tracks\n",
    "                tracker.update_tracks(detections)\n",
    "                \n",
    "                # Detect overtakes\n",
    "                tracker.detect_overtakes()\n",
    "            \n",
    "            # Visualize\n",
    "            viz_frame = visualizer.draw_frame(frame)\n",
    "            \n",
    "            # Save frame\n",
    "            if CONFIG['output_video']:\n",
    "                out.write(viz_frame)\n",
    "            \n",
    "            # Display\n",
    "            display_frame = cv2.resize(viz_frame, (1280, 720))\n",
    "            cv2.imshow('F1 Race Tracker', display_frame)\n",
    "            \n",
    "            # Progress\n",
    "            if tracker.frame_count % 30 == 0:\n",
    "                progress = (tracker.frame_count / total_frames) * 100 if total_frames > 0 else 0\n",
    "                print(f\"Progress: {progress:.1f}% | Frame: {tracker.frame_count} | Cars: {len(tracker.tracks)} | Overtakes: {len(tracker.overtakes)}\")\n",
    "        \n",
    "        # Handle keyboard\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            print(\"\\n‚èπÔ∏è Stopped by user\")\n",
    "            break\n",
    "        elif key == ord('p'):\n",
    "            paused = not paused\n",
    "            print(\"‚è∏Ô∏è Paused\" if paused else \"‚ñ∂Ô∏è Resumed\")\n",
    "        elif key == ord('s'):\n",
    "            cv2.imwrite(f'frame_{tracker.frame_count}.jpg', viz_frame)\n",
    "            print(f\"üíæ Saved frame_{tracker.frame_count}.jpg\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚èπÔ∏è Interrupted by user\")\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    if CONFIG['output_video']:\n",
    "        out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä RACE ANALYSIS COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bde2bb-cf0c-4ece-bf15-64288f3be40c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 7: Generate Reports\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüìà Generating analysis reports...\\n\")\n",
    "\n",
    "# Overtake Timeline\n",
    "if CONFIG['generate_timeline'] and tracker.overtakes:\n",
    "    print(\"üèÅ OVERTAKE TIMELINE:\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for i, overtake in enumerate(tracker.overtakes):\n",
    "        timestamp = timedelta(seconds=overtake.timestamp)\n",
    "        print(f\"{i+1}. [{timestamp}] {overtake.overtaking_car} overtook {overtake.overtaken_car}\")\n",
    "        print(f\"   Confidence: {overtake.confidence:.2f}\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "# Track Statistics\n",
    "print(\"üèéÔ∏è CAR STATISTICS:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for track in sorted(tracker.tracks.values(), key=lambda t: t.total_frames, reverse=True):\n",
    "    if track.confidence >= CONFIG['min_track_confidence']:\n",
    "        print(f\"{track.name}:\")\n",
    "        print(f\"   Frames tracked: {track.total_frames}\")\n",
    "        print(f\"   Confidence: {track.confidence}\")\n",
    "        \n",
    "        if track.positions:\n",
    "            positions = list(track.positions)\n",
    "            total_distance = sum(\n",
    "                np.linalg.norm(np.array(positions[i+1]) - np.array(positions[i]))\n",
    "                for i in range(len(positions) - 1)\n",
    "            )\n",
    "            print(f\"   Distance traveled: {total_distance:.1f} pixels\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Save telemetry\n",
    "if CONFIG['save_telemetry']:\n",
    "    telemetry_data = {\n",
    "        'metadata': {\n",
    "            'total_frames': tracker.frame_count,\n",
    "            'fps': fps,\n",
    "            'resolution': [frame_width, frame_height],\n",
    "        },\n",
    "        'cars': {\n",
    "            name: [\n",
    "                {\n",
    "                    'frame': entry['frame'],\n",
    "                    'position': entry['position'],\n",
    "                    'velocity': entry['velocity']\n",
    "                }\n",
    "                for entry in data\n",
    "            ]\n",
    "            for name, data in tracker.telemetry.items()\n",
    "        },\n",
    "        'overtakes': [\n",
    "            {\n",
    "                'frame': ov.frame,\n",
    "                'timestamp': ov.timestamp,\n",
    "                'overtaking_car': ov.overtaking_car,\n",
    "                'overtaken_car': ov.overtaken_car,\n",
    "                'confidence': ov.confidence\n",
    "            }\n",
    "            for ov in tracker.overtakes\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    with open(CONFIG['telemetry_path'], 'w') as f:\n",
    "        json.dump(telemetry_data, f, indent=2)\n",
    "    \n",
    "    print(f\"üíæ Telemetry saved to: {CONFIG['telemetry_path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06d3085-2a39-48de-9d22-b81491f58430",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 8: Visualization Plots\n",
    "# ============================================================================\n",
    "\n",
    "if tracker.telemetry:\n",
    "    print(\"\\nüìä Generating position plots...\\n\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "    \n",
    "    # Position over time\n",
    "    ax1 = axes[0]\n",
    "    for car_name, data in tracker.telemetry.items():\n",
    "        frames = [entry['frame'] for entry in data]\n",
    "        positions = [entry['position'][0] for entry in data]  # X position\n",
    "        \n",
    "        if len(frames) > 10:\n",
    "            ax1.plot(frames, positions, label=car_name, linewidth=2)\n",
    "    \n",
    "    ax1.set_xlabel('Frame')\n",
    "    ax1.set_ylabel('X Position (pixels)')\n",
    "    ax1.set_title('Car Positions Over Time')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Mark overtakes\n",
    "    for overtake in tracker.overtakes:\n",
    "        ax1.axvline(x=overtake.frame, color='red', linestyle='--', alpha=0.5)\n",
    "        ax1.text(overtake.frame, ax1.get_ylim()[1], 'üèÅ', \n",
    "                ha='center', va='bottom', fontsize=12)\n",
    "    \n",
    "    # Speed estimates\n",
    "    ax2 = axes[1]\n",
    "    for car_name, data in tracker.telemetry.items():\n",
    "        frames = [entry['frame'] for entry in data]\n",
    "        speeds = [np.linalg.norm(entry['velocity']) for entry in data]\n",
    "        \n",
    "        if len(frames) > 10:\n",
    "            ax2.plot(frames, speeds, label=car_name, linewidth=2)\n",
    "    \n",
    "    ax2.set_xlabel('Frame')\n",
    "    ax2.set_ylabel('Speed (pixels/frame)')\n",
    "    ax2.set_title('Relative Speed Over Time')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('race_analysis_plots.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"üíæ Saved race_analysis_plots.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92beb86-04c4-4797-b9bd-11a0de70d300",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# ============"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
